version: '3.8'
  
  ############### NEW INFO ADDITIONAL TO AIRFLOW STANDARD INFO ############################
services:
  # mysql:
  #   # Service Name
  #   image: mysql:latest  # Docker image for SQL Container
  #   container_name: mysql
  #   # ports:
  #   #   - "3306:3306"  # Mapping ports
  #   expose: 
  #     - "3306"
  #   environment:
  #     MYSQL_ROOT_PASSWORD: airflow  # Root password
  #     MYSQL_DATABASE: project_3  # MySQL database
  #   volumes:
  #     - mysql_data:/var/lib/mysql
  #   healthcheck:
  #     test: ["CMD", "mysqladmin", "ping", "-h", "localhost"]  # Verify health
  #     interval: 10s  # Frecuency of health verification
  #     timeout: 5s  # Max wait for health verification
  #     retries: 3  # Number of retries for health verification
  #     start_period: 10s  # Waiting time before health verification
  #   restart: always  
  #   networks:
  #   - network1

  # API for request given by users
  fastapi:
    # build: ./docker/fastapi
    image: candemas/project3:fastapi
    container_name: fastapi
    ports:
      - '8085:8085'
    # volumes:
    #   - ./docker/fastapi/code/fast_api_main.py:/fast_api_main.py
    restart: always
    networks:
    - network1

  # MinIO - we call it as s3
  s3:
    container_name: Minio
    command: server /data --console-address ":8083" --address :8084
    environment:
      - MINIO_ROOT_USER=admin
      - MINIO_ROOT_PASSWORD=supersecret
    image: quay.io/minio/minio:latest
    ports:
      # - '8084:8084' # API
      - '8083:8083' # Browser
    expose: 
      - 8084
    volumes:
      - ./minio_data:/data
    restart: unless-stopped
    networks:
    - network1

  jupyter:
    # build: ./docker/jupyter
    image: candemas/project3:jupyter
    container_name: jupyter
    environment:
      # Jupyter configuration to use MinIO as S3 backend
      MLFLOW_S3_ENDPOINT_URL: http://10.43.101.158:8083  # It must match with the service name and MinIO port
      AWS_ACCESS_KEY_ID: admin  # MinIO credentials
      AWS_SECRET_ACCESS_KEY: supersecret
    ports:
      - "8088:8088"
    restart: always
    volumes:
    - ../docker/jupyter:/jupyter_code
    stdin_open: true
    tty: true
    networks:
    - network1

  # streamlit:
  #   # build: ./docker/streamlit
  #   image: candemas/project3:streamlit
  #   container_name: streamlit
  #   ports:
  #     - "8082:8082"
  #   restart: always
  #   # volumes:
  #   # - ./images:/images
  #   # - ./docker/streamlit/code:/streamlit_code
  #   command: > 
  #     streamlit run streamlit_code/app.py 
  #     --server.port 8082
  #   networks:
  #   - network1

volumes:
  # mysql_data:
  minio_data:

networks:
  # We use external network because we are using the data given by the "project 2" who has their own network.
  # First you need to identify the network name with the following command: `docker network ls`
  # Then add the network name after "name" and add "external" to "true"
  # This will make understand this docker compose that you are using and external network that is available
  network1:
      name: project-3-network
      external: true